% !TEX root =main.tex


\section{SO-PoR's Full Evaluation}\label{Full-Evaluation}

In the following, we  provide a full analysis of SO-PoR and  compare its properties and detailed costs to those protocols that support outsourced PoR (O-PoR), i.e. \cite{armknecht2014outsourced,xu2016lightweight,Storage-Time}. 
Note, there are two protocols  proposed in  \cite{Storage-Time}; in the following, we only consider the one that supports public verifiability, i.e. basic PoSt. Recall,  we consider a generic case where a client outsources $z$ verifications and  in our cost analysis, we also compare SO-PoR cost with the cost of the most efficient privately verifiable PoR \cite{DBLP:conf/asiacrypt/ShachamW08}, too. 

%The basic PoSt in \cite{Storage-Time} supports public verification; that means a smart cotnract can play the role of a validator. 


\noindent\textbf{\textit{Properties}}. We start with a crucial feature that any O-PoR must have: real-time detection. Recall,  real-time detection requires a client to receive a correct verification result in (almost)  real-time without the need for it to re-execute the verification itself. This is offered only by SO-PoR. By contrast, in \cite{armknecht2014outsourced}  the auditor may never notify the  client, even if it does, its notification would not be reliable, and the client has to redo the verification to verify the auditor's claim. Similarly, in \cite{xu2016lightweight} the client has to fully trust the auditor to get notified on-time. The basic PoSt in \cite{Storage-Time} requires the server to collect all PoR's and send them to a validator in one go. This means, the client and validator cannot detect data tampering in real-time if a subset of the PoR's are invalid; instead they need to wait until $z$ PoR's are collected by the server.  So, \cite{armknecht2014outsourced,xu2016lightweight,Storage-Time} are not suitable for the cases where a client must be notified by a potentially malicious auditor as soon as an unauthorised modification on the sensitive data is detected.  The  fair payment is another vital property in O-PoR, as the cloud server  and auditor must be paid fairly, in the \emph{real world} when they serve a client. This feature is explicitly captured by  only SO-PoR.  The protocols in \cite{armknecht2014outsourced,xu2016lightweight} do not have any mechanism in place. In \cite{armknecht2014outsourced}, one may allow  the auditor to pay the server on the client's behalf. But, this is problematic.   The server and auditor can collude to save costs, in a way that the server  generates accepting proofs for the client but generates no proof for the auditor, and still the auditor pays it. This violates the fair payment and cannot be detected by the client unless it performs all the verification itself. On the other hand, a client in \cite{xu2016lightweight}  has to fully trust the auditor (with the payment too), otherwise the auditor can collude with the server to violate the fair payment. The authors of \cite{Storage-Time}  briefly state that the basic PoSt's verification can be performed by a smart contract who, after ensuring the proofs are valid,  pays the server. Nevertheless, as stated previously, the verification cost of this protocol is too high for a smart contract, i.e. imposes at least $z$ modular exponentiations over RSA modulus and requires a high number of messages logarithmic with the file size to be sent to the contract. Thus, even though it can support fair payment \emph{in theory}, it is very costly in practice.  Another  property is the cost of onboarding a new verifier, as it determines how flexible the client can be, to pick a new auditor when its current one is misbehaving. This cost in \cite{armknecht2014outsourced} is significantly  high, as it requires the verifier to download the entire file, generate metadata, and prove in zero-knowledge the correctness of metadata to the client. But, that cost in SO-PoR and \cite{xu2016lightweight,Storage-Time} is very low as the client only sends them a small set of parameters without the need to access the outsourced data.  Furthermore, as stated above, a client in  \cite{xu2016lightweight} has to fully trust the auditor with the correctness of verification but this is not the case in   SO-PoR and \cite{armknecht2014outsourced,Storage-Time}, as they consider a potentially malicious auditor (under different assumptions).  Table \ref{table::O-PoR-Property} summaries the result of  the comparison between the four protocols' main properties. 

\input{table-PoR-property.tex}


 \noindent\textbf{\textit{Computation Complexity}}. In our analysis, we do not take into account the cost of erasure-coding a file, as it is identical in all schemes. We first analyse the computation cost of  SO-PoR.  A client in step \ref{gen-client-server-tags} performs $n$  multiplications and $n$ additions to generate permanent tags. In step \ref{Gen-Disposable-Tags}, it performs $cz$ multiplications and $cz$ additions to generate disposable tags for $z$ verifications. The client in step \ref{Gen-Puzzles-} invokes $\mathtt{GenPuz(.)}$ function, in C-TLP, that  costs $O(z)$. So, the client's total computation cost of preparing and storing a file is $O(n+cz)$. Now we consider the cloud server's cost that can be categorised into two classes: (a) solving a puzzle: $\mathtt{SolvPuz}()$, run only once, and (b) generating PoR run for each verification. In particular, the cloud in step \ref{Solve-Puzzle-Regen-Indices},  invokes $\mathtt{SolvPuz}()$, in C-TLP, that costs $O(T z)$ this includes the cost in step \ref{fully-recover-l} as well. To compute proofs, in step \ref{Gen-PoR}, it performs $2 c z$ multiplications and  $2 c z$ additions. So, the server to generate proof   is $O(cz)$. Next, we analyse the cost of the smart contract. In step \ref{check-hash}, it invokes $\mathtt{Verify}(.)$, in C-TLP, that in total costs $O(z)$, this involves invoking $z$  hash function's instances. Also, the contract in step \ref{verify-PoR} performs $z(1+c)$ and $z(1+c)$ modular multiplications and additions respectively. Thus, the total cost  is $O(cz)$ involving  mainly modular additions and multiplications.
%\cite{armknecht2014outsourced,xu2016lightweight}.

Now we analyse the computation cost of \cite{armknecht2014outsourced}. To prepare file tags, a client performs: $n$ multiplications and $n$ additions. Also, to verify tags generated by the auditor, the client  has to engage in a zero-knowledge protocol that requires it to carry out   $6n$ exponentiations and $2 n$ multiplications. Therefore, the client's computation complexity is $O(n)$. Also, the auditor in total performs $3n$ multiplications, $3 n$ additions and $3 n$ exponentiations to prepare file's metadata, so its complexity at this phase is $O(n)$. For the cloud to generate $z$ proofs, in total it performs $2z(c+c')$ multiplications and the same number of additions, where $c'$ is the number of challenges sent by the auditor to the cloud (on client's behalf) and $c>c'$, e.g. $c'=(0.1)c$. So, the total complexity of the cloud is $O(z  (c+c'))$. Next, we consider the verification cost. The auditor performs $z(1+c) $ multiplications and $z(1+c) $ additions to verify PoR. It also  performs $2cz $ additions in \textit{CheckLog} algorithm that requires the client to perform $z(2c+1)$ additions and $cz$ multiplications. Nevertheless, as discussed in Section \ref{Related-Work}, running only \textit{CheckLog} does not allow the client to detect a misbehaving auditor. Thus, it has to run \textit{ProveLog} too, that requires the client to perform $cz$ multiplications and $cz$ additions and requires the auditor to reveal all its secrets to the client. So, the total verification complexity is $O(cz)$. Now we turn our attention to the computation complexity of \cite{xu2016lightweight}. To prepare metadata, the client needs to perform $2  n$ multiplication and $2  n$ additions, so the client's complexity is $O(n)$. For the cloud to generate a proof it needs to perform $3  z$ exponentiations,  $z  (3  c+6)$ multiplications  and $z  (3 c+2)$ additions. So, its complexity is $O(cz)$. On the other hand, the verifier performs $cz$ exponentiations to compute  challenges. To verify the proof, it carries out  $6 z$ exponentiations, $cz$ multiplications,    $cz$ additions, and  $7  z$ pairings. Therefore, the verifier complexity is  $O(cz)$ dominated by expensive exponentiations and pairing operations. Also, we analyse the  computation cost of efficient privately verifiable PoR  in \cite{DBLP:conf/asiacrypt/ShachamW08}. A client in the store phase performs $n$ multiplications and $n$ additions to construct the tags. So, its complexity is $O(n)$. A server performs $2cz$ multiplications and $2cz$ additions to generate proofs, so in total $4cz$ or $O(cz)$ modular operations for $z$ verifications it carries out. The client, as verifier this time, performs in total $2z(1+c)$ or $O(z(1+c))$ modular operations.  Next, we turn our attention to  \cite{Storage-Time}, and evaluate the cost of the protocol that supports public verifiability, basic PoSt. As stated by the authors, they add a VDF to  the PoR construction in \cite{Filecoin} which uses a Merkle tree-based PoR. Since,  this PoR scheme only involves invocations of hash function, here we only focus on VDF cost as it dominates other computation costs. We assume that the most efficient    publicly verifiable delay function VDF \cite{Wesolowski19} is used.  In the setup, the client constructs a Merkle tree on the entire data  by invoking a hash function many times and also generates a random challenge. We ignore these costs as they are dominated by VDF's costs. To generate $z$ PoR's, the server invokes VDF $z$ times that in total runs in time period $T$. This involves $3Tz$ modular exponentiations over $\mathbb{Z}_{\scriptscriptstyle N}$ (where $N$ is a RSA modulus), and $Tz$ modular multiplications. Therefore, its complexity is $O(Tz)$. For a validator to ckeck the proofs output by VDF, it performs $3z$ modular exponentiations over $\mathbb{Z}^{*}_{\scriptscriptstyle N}$ (or $\bmod\phi(N)$). So the verifier's complexity is $O(z)$. 



Now we compare the protocols above. The verification in SO-PoR is much faster than the other three protocols; firstly, it requires no exponentiations in this phase, whereas \cite{xu2016lightweight,Storage-Time} do, and secondly, it requires $\frac{9c+3}{2(1+c)}$ times fewer computation than \cite{armknecht2014outsourced};  Specifically, when $c=460$,  SO-PoR verification requires about $4.5$ times fewer computation than the verification in \cite{armknecht2014outsourced} needs. In SO-PoR, the cloud server needs to perform $Tz$ exponentiations to solve puzzles, however this is independent of the file size. The sever in \cite{Storage-Time} also performs $3Tz$ modular exponentiations, which is  $3$ times higher than the number of exponentiations done by the server in SO-PoR. The  protocols in \cite{armknecht2014outsourced,DBLP:conf/asiacrypt/ShachamW08} do not include the puzzle-solving procedure (and they do not offer all features that SO-PoR does).  Furthermore, the proving cost in SO-PoR is similar to that of in \cite{armknecht2014outsourced}, and is  much better than \cite{xu2016lightweight}, as the latter one requires both exponentiations and pairing operations while the prove algorithm in SO-PoR  does not involve any exponentiations. The  proving cost in \cite{Storage-Time} is the lowest, as it requires only invocations of a hash function.  Also, the store phase in SO-PoR has a much lower computation cost than the one in \cite{armknecht2014outsourced}. The reason is that the number of exponentiations required (in this phase) in SO-PoR is independent of file size and is only linear with the number of delegated verifications; however, the number of exponentiations in \cite{armknecht2014outsourced} is linear with the file size. For instance, when $||{\bm{F}}||=1$-GB, the  total number of blocks is:   $n=\frac{1-\text{GB}}{128-\text{bit}}=625\times 10^{\scriptscriptstyle 5}$. Since the number of exponentiations in \cite{armknecht2014outsourced} is linear with the number of blocks, i.e. $9n$, the total number of exponentiations imposed by store algorithm is: $5625\times 10^{\scriptscriptstyle 5}$ which is very high. This is the reason why in the experiment in \cite{armknecht2014outsourced} only a small file size: $64$-MB, is used, that can be stored locally without the need to use  cloud storage, in the first place.   Now, we turn our attention to SO-PoR. Let the verification be done every month for a $10$-year period, in this case,  $z=120$.  So, the total number of exponentiations required by the store in SO-PoR is $121$. This means the store phase in SO-PoR requires over $46\times 10^{\scriptscriptstyle 5}$ times  fewer exponentiations than the one in \cite{armknecht2014outsourced} needs. On the other hand, the store algorithm in \cite{xu2016lightweight} does not involve any exponentiations; however, its  number of modular additions and multiplication  is higher than the ones imposed by the store in SO-PoR. The  store cost in \cite{Storage-Time} is the lowest, as it requires only invocations of a hash function. Furthermore, the verification and prove cost of SO-PoR and privately verifiable PoR \cite{DBLP:conf/asiacrypt/ShachamW08} are identical. 




%\noindent\textbf{\textit{I/O Cost}}. In SO-PoR and \cite{xu2016lightweight,armknecht2014outsourced}, for a server to generate a PoR, it only needs to access a constant number of blocks. Therefore, their total I/O cost is $O(z)$. But, unlike the majority of existing PoR schemes, in \cite{Storage-Time}  the server has to access the \emph{entire file blocks} to generate a PoR, so its cost is much higher than the rest. In particular, its total I/O cost is $O(|F|z)$. Note that I/O cost plays a crucial role in the scalability of the server and its ability to serve multiple clients/queries degrades when the I/O cost is significantly high. 




%Note, the total number of exponentiations required to prepare a file is $9\cdot n$. 

%Therefore, after running  \textit{ProveLog}, the auditor (who may not trust the client) has to   run again store algorithm which requires: (a) $9\cdot n$ exponentiations, and (b) downloading the entire file. 
 
  
% 
%  \noindent\textbf{\textit{I/O Cost}}. 
%  
%In SO-PoR and \cite{armknecht2014outsourced,DBLP:conf/asiacrypt/ShachamW08}, for a server to generate a PoR, it only needs to access a constant number of blocks.
%  
%  
%  Therefore, their I/O cost in total is $O(z)$. However, in \cite{Storage-Time} the server has to access the entire file blocks to generate a proof, therefore its total I/O complexity is much higher, i.e. $O(|F|z)$.
% 
% 
 
 
 \
 
  \noindent\textbf{\textit{Communication Complexity}}. In our analysis, we do not take into account the communication cost of uploading an encoded file, i.e. $||{\bm{F}}||$, when the client for the first time sends it to the cloud, as it is identical in all schemes. The communication cost of SO-PoR is as follows. The client, in step \ref{Outsource-File}, sends $n$ permanent tags, $z c$ disposable tags, and the output of $\mathtt{GenPuz}(.)$ to the server and contract, where each (permanent/disposable) tag: $\sigma_{\scriptscriptstyle j}\in \mathbb{F}_p$ and $|\sigma_{\scriptscriptstyle j}|=128$-bit. Note the client also sends a few public parameters: $\hat{pk}$, whose size is short.  Therefore, the client's bandwidth  is: $128  (n+ c  z+19 z)$ bits, while its communication complexity is $O(n+c z)$. The cloud in step \ref{Register-Proofs}, sends $z$ pairs $(\mu_{\scriptscriptstyle j},\xi_{\scriptscriptstyle j})$, where $\mu_{\scriptscriptstyle j},\xi_{\scriptscriptstyle j}\in \mathbb{F}_p$ and $|\mu_{\scriptscriptstyle j}|=|\xi_{\scriptscriptstyle j}|=128$-bit. Also, in step \ref{fully-recover-l}, it sends to the contract the output of $\mathtt{Prove}(.)$, in  C-TLP, whose total size is $628 z$ bits. So, the clouds total bandwidth is about $884  z$ bits and its complexity is $O(z)$ which is independent of and constant in the file size. 
 
 The communication cost of \cite{armknecht2014outsourced} is as follows. The client sends $n$ tags to the server, where the size of each tag is about $128$ bits. So its bandwidth is $128  n$, and its complexity is  $O(n)$. The auditor also sends $n$ tags to the server, where each tag size is also $128$ bits. It also sends the tags to the client along with $zk$ proofs that contain $4n$ elements in total,  where $2n$ of them are elements of $\mathbb{Z}_{\scriptscriptstyle N}$ and each element size is  $2048$ bits, and each of the other $2n$ elements is $160$ bits long. Also, the auditor in \textit{ProveLog} sends $z$ pairs to the client with the  bandwidth of $256  z$. So, the auditor's total bandwidth and complexity is  $4672  n+256  z$ and $O(n+z)$ respectively. Moreover, the cloud sends the entire file, $F$, to the auditor in the store phase and also sends $2  z$ pairs of PoR to the auditor, where each element of the pair is of size $128$ bits. Therefore, the cloud's total  bandwidth is $||{\bm{F}}||+256  z$, while its complexity is $O(||{\bm{F}}||+z)$. Note that the cloud's proof size complexity is constant and independent of the file size, i.e. $O(1)$. Now, we analyse the communication cost of  \cite{xu2016lightweight}. The client bandwidth and complexity are $2048  n$ and $O(n)$ respectively, as it sends to the cloud $2  n$ tags, where each tag size is $1024$ bits. Also, the cloud bandwidth  and complexity are $6144 z$ and $O(z)$ respectively, as for each verification the cloud sends to the verifier $6$ elements each of them is $1024$-bit long. Furthermore, in \cite{DBLP:conf/asiacrypt/ShachamW08} the client bandwidth in the store phase is $128n$, while the server  bandwidth is $256z$. In this scheme, the complexity of a proof size is $O(1)$. In \cite{Storage-Time}, the client can send only the file and random challenge of size $128$-bit to the server, who creates a Merkle tree on top of the file's blocks. Therefore, the client's bandwidth is  $128$-bit. The server sends to the verifier $cz$ PoR proofs that cost it in total  at least $128cz\log(n)$ bits. Also, the server sends VDF's proofs for $z$ outputs, that cost in total $4096z$.  Therefore, the server's total bandwidth is $(128cz\log n)+4096z$. The reason the cost involves $c$ (the number of challenges) is that unlike the other three schemes, this scheme does not support a linear combination of tags/proofs (e.g. homomorphic tags), and in each proving phase $c$ proofs are generated.  Furthermore, in this scheme, the complexity of a proof size is logarithmic with the number of file blocks,  $O(\log(n))$.
 
 To conclude, the verifier-side bandwidth of SO-PoR (and \cite{xu2016lightweight,Storage-Time}) is much lower than \cite{armknecht2014outsourced}. For instance, when $||{\bm{F}}||=1$-GB and $z=100$, a verifier in SO-PoR requires $62\times 10^{\scriptscriptstyle 6}$  fewer bits than the one in \cite{armknecht2014outsourced} does. A client in SO-PoR has a higher bandwidth than it would have in the rest of the protocols. But, this cost is one-off, at the setup phase.  The server-side bandwidth of SO-PoR is the lowest;  for instance (for the same parameters above) a server in SO-PoR requires $9\times 10^{\scriptscriptstyle4}$,  $7$, and $1729$ times fewer bits  than those required in \cite{armknecht2014outsourced}, \cite{xu2016lightweight} and \cite{Storage-Time} respectively.   Moreover, \cite{Storage-Time} has the worst proof size complexity, which is logarithmic to the file size; while the proof size complexity of the rest of the schemes  is constant.  Thus, SO-PoR's server-side bandwidth is significantly lower than the rest  while having constant proof size. 
 
 
 
 

 
 
 
 \begin{remark}
In \cite{armknecht2014outsourced}, the  additional costs   to secure parties against a malicious client stem from only the store phase, where  an auditor downloads the entire file, generates zero-knowledge proofs, and has the client sign them after verifying the proofs. Therefore, the overheads of proving and verifying phases, in this protocol, would remain unchanged if the protocol considers an honest client.  
 \end{remark}